{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "degBit = 11\n",
    "degStable = 11\n",
    "delta = 1/6\n",
    "\n",
    "def binomial_pdf(n, p, x):\n",
    "    return binomial(n, x) * p ^ x * (1 - p) ^ (n-x)\n",
    "\n",
    "# Pr[X >= x]\n",
    "def binomial_ncdf(n, p, x):\n",
    "    probSum = 0.0\n",
    "    for i in range(x, n + 1):\n",
    "        probSum = probSum + binomial_pdf(n, p, i)\n",
    "    return probSum\n",
    "\n",
    "# phi(targetP) = Pr[X >= x], return x\n",
    "def binomial_ncdf_inverse(n, p, targetP):\n",
    "    for i in range(1, n):\n",
    "        ncdf_p = binomial_ncdf(n, p, i)\n",
    "        if ncdf_p < targetP:\n",
    "            return i - 1\n",
    "    return n\n",
    "\n",
    "\n",
    "# https://stats.stackexchange.com/questions/394960/variance-of-normal-order-statistics\n",
    "# Variance for quantile\n",
    "# TODO: verify\n",
    "def binomial_inverse_variance(N, p, inverse, M):\n",
    "\treturn p * (1-p) / ((M+2) * (binomial_pdf(N, p, inverse)^2))\n",
    "\n",
    "## Lower bound via taking advantage of discrete RV\n",
    "# where V < mu\n",
    "def chebyshevLowerBound(V, mu, variance):\n",
    "\treturn min(variance / (mu - V)^2, 1)\n",
    "\n",
    "## Upper bound via taking advantage of discrete RV\n",
    "# where V > mu and we are looking for Pr[mu < V]\n",
    "def chebyshevUpperBound(V, mu, variance):\n",
    "\treturn 1 - min(variance / (mu - V)^2, 0)\n",
    "\n",
    "def pr_G_error_given_E(E, degBit, degStable, delta, k, M, pG):\n",
    "\t# a lower bound for the expectation of G\n",
    "\tnStabilizersForG = degBit * degStable - degStable * E\n",
    "\tnStabilizersForGPrime = floor((1 - delta) * degBit * degStable) - degStable * E\n",
    "\n",
    "\tif nStabilizersForG <= 0:\n",
    "\t\treturn 1\n",
    "\texpectedG = binomial_ncdf_inverse(nStabilizersForG, pG, k / M)\n",
    "\tvarianceG = binomial_inverse_variance(nStabilizersForG, pG, expectedG, M)\n",
    "\t# print(expectedG, varianceG, pG, nStabilizersForG)\n",
    "\n",
    "\t# expectedGPrime = expectedG * (1 - delta)\n",
    "\texpectedGPrime = binomial_ncdf_inverse(nStabilizersForGPrime, pG, k / M)\n",
    "\t# varianceGPrime = varianceG * (1 - delta) ^ 0.5\n",
    "\n",
    "\tgPrimeForError = (3 * degBit * E + E - delta * E) / (3 * degBit - 1 + delta)\n",
    "\t\n",
    "\t# Note: this gives an upper bound for error\n",
    "\t# Just return the probability that Pr[G'\n",
    "\tif gPrimeForError == expectedGPrime:\n",
    "\t\treturn 1#chebyshevUpperBound(gPrimeForError + 1, expectedGPrime, varianceGPrime)\n",
    "\telif gPrimeForError > expectedGPrime:\n",
    "\t\treturn 1#chebyshevUpperBound(gPrimeForError, expectedGPrime, varianceGPrime)\n",
    "\telse:\n",
    "\t\t# Just use varianceG for a better upper bound\n",
    "\t\treturn chebyshevLowerBound(gPrimeForError, expectedGPrime, varianceG)\n",
    "\n",
    "def pr_G_and_E_error(n_E, p_E, E, degBit, delta, k, M, pG):\n",
    "\tprE = binomial_pdf(n_E, p_E, E)\n",
    "\treturn prE * pr_G_error_given_E(E, degBit, degStable, delta, k, M, pG)\n",
    "\n",
    "\n",
    "def calc_pr_indep_G_E_lt_v_for_k(degBit, stableDeg, delta, v, k, pError, nE, pE, pG, M):\n",
    "\tmaxE = nE\n",
    "\tprLtV = 0\n",
    "\tfor e in range(0, maxE):\n",
    "\t\tprLtV = prLtV + pr_G_and_E_error(nE, pE, e, degBit, delta, k, M, pG)\n",
    "\treturn prLtV\n",
    "\n",
    "def calc_pr_indep_G_E_lt_v(bitDeg, stableDeg, delta, v, kRange, pError, M):\n",
    "\tpG = 0.5 - 0.5 * (1 - 2 * pError)^stableDeg\n",
    "\tpE = 0.5 + 0.5 * (1 - 2 * pError)^stableDeg - (1 - pError)^stableDeg\n",
    "\tnG = floor(bitDeg * stableDeg)\n",
    "\tnE = floor(bitDeg * stableDeg)\n",
    "\n",
    "\terror_prob = 1\n",
    "\tfor k in range(*kRange):\n",
    "\t\ttmp = calc_pr_indep_G_E_lt_v_for_k(bitDeg, stableDeg, delta, v, k, pError, nE, pE, pG, M)\n",
    "\t\tprint(k, tmp)\n",
    "\t\terror_prob = error_prob * tmp\n",
    "\treturn error_prob\n",
    "\n",
    "# TODO: make some plots?? (After LaTeX to ensure that I have some soundness to my arguments)\n",
    "error_prob = calc_pr_indep_G_E_lt_v(degBit, degStable, delta, 1/6, (1, 100), 0.05, 10000)\n",
    "error_prob\n",
    "\n",
    "# 1.48343651109348e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.48343651109348e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.352973359326478\n",
      "2 0.0853387115853901\n",
      "3 0.0488442052541024\n",
      "4 0.0419293686978078\n",
      "5 0.0219213789375707\n",
      "6 0.0133462849078472\n",
      "7 0.0133462849078472\n",
      "8 0.0133391426016529\n",
      "9 0.00642385499978010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.06410449056573e-14"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### WRONG METHOD BELOW\n",
    "degBit = 11\n",
    "degStable = 11\n",
    "delta = 1/6\n",
    "\n",
    "def binomial_pdf(n, p, x):\n",
    "    return binomial(n, x) * p ^ x * (1 - p) ^ (n-x)\n",
    "\n",
    "# Pr[X >= x]\n",
    "def binomial_ncdf(n, p, x):\n",
    "    probSum = 0.0\n",
    "    for i in range(x, n + 1):\n",
    "        probSum = probSum + binomial_pdf(n, p, i)\n",
    "    return probSum\n",
    "\n",
    "# phi(targetP) = Pr[X >= x], return x\n",
    "def binomial_ncdf_inverse(n, p, targetP):\n",
    "    for i in range(1, n):\n",
    "        ncdf_p = binomial_ncdf(n, p, i)\n",
    "        if ncdf_p < targetP:\n",
    "            return i - 1\n",
    "    return n\n",
    "\n",
    "\n",
    "# https://stats.stackexchange.com/questions/394960/variance-of-normal-order-statistics\n",
    "# Variance for quantile\n",
    "# TODO: verify\n",
    "def binomial_inverse_variance(N, p, inverse, M):\n",
    "\treturn p * (1-p) / ((M+2) * (binomial_pdf(N, p, inverse)^2))\n",
    "\n",
    "## Lower bound via taking advantage of discrete RV\n",
    "# where V < mu\n",
    "def chebyshevLowerBound(V, mu, variance):\n",
    "\treturn min(variance / (mu - V)^2, 1)\n",
    "\n",
    "## Upper bound via taking advantage of discrete RV\n",
    "# where V > mu and we are looking for Pr[mu < V]\n",
    "def chebyshevUpperBound(V, mu, variance):\n",
    "\treturn 1 - min(variance / (mu - V)^2, 0)\n",
    "\n",
    "def pr_G_error_given_E(E, degBit, degStable, delta, k, M, pG):\n",
    "\t# a lower bound for the expectation of G\n",
    "\tnStabilizersForG = degBit * degStable - degStable * E\n",
    "\tif nStabilizersForG <= 0:\n",
    "\t\treturn 1\n",
    "\texpectedG = binomial_ncdf_inverse(nStabilizersForG, pG, k / M)\n",
    "\tvarianceG = binomial_inverse_variance(nStabilizersForG, pG, expectedG, M)\n",
    "\t# print(expectedG, varianceG, pG, nStabilizersForG)\n",
    "\n",
    "\texpectedGPrime = expectedG * (1 - delta)\n",
    "\tvarianceGPrime = varianceG * (1 - delta) ^ 0.5\n",
    "\n",
    "\tgPrimeForError = (3 * degBit * E + E - delta * E) / (3 * degBit - 1 + delta)\n",
    "\t\n",
    "\t# Note: this gives an upper bound for error\n",
    "\t# Just return the probability that Pr[G'\n",
    "\tif gPrimeForError == expectedGPrime:\n",
    "\t\treturn 1#chebyshevUpperBound(gPrimeForError + 1, expectedGPrime, varianceGPrime)\n",
    "\telif gPrimeForError > expectedGPrime:\n",
    "\t\treturn 1#chebyshevUpperBound(gPrimeForError, expectedGPrime, varianceGPrime)\n",
    "\telse:\n",
    "\t\treturn chebyshevLowerBound(gPrimeForError, expectedGPrime, varianceGPrime)\n",
    "\n",
    "def pr_G_and_E_error(n_E, p_E, E, degBit, delta, k, M, pG):\n",
    "\tprE = binomial_pdf(n_E, p_E, E)\n",
    "\treturn prE * pr_G_error_given_E(E, degBit, degStable, delta, k, M, pG)\n",
    "\n",
    "\n",
    "def calc_pr_indep_G_E_lt_v_for_k(degBit, stableDeg, delta, v, k, pError, nE, pE, pG, M):\n",
    "\tmaxE = nE\n",
    "\tprLtV = 0\n",
    "\tfor e in range(0, maxE):\n",
    "\t\tprLtV = prLtV + pr_G_and_E_error(nE, pE, e, degBit, delta, k, M, pG)\n",
    "\treturn prLtV\n",
    "\n",
    "def calc_pr_indep_G_E_lt_v(bitDeg, stableDeg, delta, v, kRange, pError, M):\n",
    "\tpG = 0.5 - 0.5 * (1 - 2 * pError)^stableDeg\n",
    "\tpE = 0.5 + 0.5 * (1 - 2 * pError)^stableDeg - (1 - pError)^stableDeg\n",
    "\tnG = floor(bitDeg * stableDeg)\n",
    "\tnE = floor(bitDeg * stableDeg)\n",
    "\n",
    "\terror_prob = 1\n",
    "\tfor k in range(*kRange):\n",
    "\t\ttmp = calc_pr_indep_G_E_lt_v_for_k(bitDeg, stableDeg, delta, v, k, pError, nE, pE, pG, M)\n",
    "\t\tprint(k, tmp)\n",
    "\t\terror_prob = error_prob * tmp\n",
    "\treturn error_prob\n",
    "\n",
    "# TODO: make some plots?? (After LaTeX to ensure that I have some soundness to my arguments)\n",
    "error_prob = calc_pr_indep_G_E_lt_v(degBit, degStable, delta, 1/6, (1, 10), 0.01, 1000)\n",
    "error_prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
